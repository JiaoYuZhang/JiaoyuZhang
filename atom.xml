<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Joey&#39;s Notes</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://jiaoyuzhang.github.io/"/>
  <updated>2019-03-29T17:47:26.625Z</updated>
  <id>https://jiaoyuzhang.github.io/</id>
  
  <author>
    <name>Joey Zhang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>论文阅读-darts</title>
    <link href="https://jiaoyuzhang.github.io/2019/03/29/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-darts/"/>
    <id>https://jiaoyuzhang.github.io/2019/03/29/论文阅读-darts/</id>
    <published>2019-03-29T15:06:07.000Z</published>
    <updated>2019-03-29T17:47:26.625Z</updated>
    
    <content type="html"><![CDATA[<p>DARTS：架构搜索的可微解决</p><p>论文： DARTS: Differentiable Architecture Search 【<a href="https://arxiv.org/abs/1806.09055" target="_blank" rel="noopener">pdf</a>】【 <a href="https://github.com/quark0/darts" target="_blank" rel="noopener">code</a>】</p><p>作者：<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H" target="_blank" rel="noopener">Hanxiao Liu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Simonyan%2C+K" target="_blank" rel="noopener">Karen Simonyan</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y" target="_blank" rel="noopener">Yiming Yang</a></p><h2 id="第一部分-什么是神经网络架构搜索"><a href="#第一部分-什么是神经网络架构搜索" class="headerlink" title="第一部分 什么是神经网络架构搜索"></a>第一部分 什么是神经网络架构搜索</h2><h3 id="1-1-神经网络架构搜索（Neural-Architecture-Search）"><a href="#1-1-神经网络架构搜索（Neural-Architecture-Search）" class="headerlink" title="1.1 神经网络架构搜索（Neural Architecture Search）"></a>1.1 神经网络架构搜索（Neural Architecture Search）</h3><p>深度学习模型在很多任务上都取得了不错的效果，但调参对于深度模型来说是一项非常苦难的事情，众多的超参数和网络结构参数会产生爆炸性的组合，常规的 random search 和 grid search 效率非常低，因此最近几年神经网络的架构搜索和超参数优化成为一个研究热点。<br>NAS通常由三部分组成。首先确定search space，然后选择search<br>strategy，最后选择评价策略并迭代优化。<br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1aiesn12ej313g09ytbk.jpg" alt><br>搜索空间：搜索空间定义了优化问题的变量。深度学习模型的性能是由网络架构参数和对应的超参数来决定的，因此只需要对复杂模型的架构参数和对应的超参数进行优化即可。</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g1aiml9o9kj30ia0i0wg5.jpg" width="250," height="250"></p><p>最开始为链式的搜索空间，然后RNN中也采用了分支搜索。</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1aip9bswoj30m00kctbg.jpg" width="250," height="250"></p><p>现在，通常使用cell来对搜索空间做“降维”，能够大大提高搜索速度。    </p><p>搜索策略：定义了使用怎样的算法可以快速、准确找到最优的网络结构参数配置。常见的搜索方法包括：随机搜索、贝叶斯优化、进化算法、强化学习、基于梯度的算法。<br>评价预估：用一些低保真的训练集来训练模型，借鉴于工程优化中的代理模型，参数级别的迁移。单次（One-Shot）架构搜索。</p><h3 id="1-2-主流架构搜索-不可微的“黑箱”优化"><a href="#1-2-主流架构搜索-不可微的“黑箱”优化" class="headerlink" title="1.2 主流架构搜索-不可微的“黑箱”优化"></a>1.2 主流架构搜索-不可微的“黑箱”优化</h3><p> 国内做AutoML，主流搜索算法是进化算法或者强化算法进行不可微搜索。强化学习：NAS、ENAS， 进化算法：</p><h2 id="第二部分-DARTS架构"><a href="#第二部分-DARTS架构" class="headerlink" title="第二部分 DARTS架构"></a>第二部分 DARTS架构</h2><h3 id="2-1-darts的整体构架"><a href="#2-1-darts的整体构架" class="headerlink" title="2. 1 darts的整体构架"></a>2. 1 darts的整体构架</h3><p>首先，我们介绍一下Darts的搜索空间与整体流程。</p><p>搜索空间：在本文中以一个cell（或者叫building block）作为一个搜索空间。它是由nodes和edges构成的有向无环图。每个node被记为 <script type="math/tex">x^{(i)}</script> ，是一个特征表示（比如feature map）。</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1aiyw5juhj306o0dut9c.jpg" width="200" height="250" align="center"></p><p>而每条边edge被记为<script type="math/tex">o^{(i,j)}</script>，它表示的是从节点<script type="math/tex">x^{(i)}</script>到<script type="math/tex">x^{(j)}</script>所采用的操作（比如3*3卷积，最大池化），当然也可以是特殊的无操作<script type="math/tex">zero</script>。这样我们就可以把搜索空间表示为：</p><script type="math/tex; mode=display">x^{(i)}=\sum_{j<i} o^{(i, j)}\left(x^{(j)}\right)</script><p>经过darts的优化获得最后的cell架构后，我们既可以把它堆叠成CNN网络，也可以递归连接成RNN网络。对于每个cell，我们规定它有两个输入和一个输出。对于CNN网络，两个输入是前两层的输出；对于RNN，两个输入时这一层的输入和上一层的状态。<br>以此为基础，我们可以看一下darts的整体流程：<br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1aj9k3khzj31080f643i.jpg" width="600" height="250" align="center"></p><ol><li>初始化时，每条边即操作是未知的</li><li>采用松弛策略，使每条边上都进行多种候选操作</li><li>采用bilevel optimazation来联合优化操作的混合概率和网络权重</li><li>采用混合操作中概率最高的操作来替换混合操作，得到最终结构</li></ol><h3 id="2-2-优化策略与近似计算"><a href="#2-2-优化策略与近似计算" class="headerlink" title="2.2 优化策略与近似计算"></a>2.2 优化策略与近似计算</h3><p>接下来我们会详细介绍darts的整个优化策略。</p><h4 id="1-将搜索空间可微化"><a href="#1-将搜索空间可微化" class="headerlink" title="1. 将搜索空间可微化"></a>1. 将搜索空间可微化</h4><p>darts通过引入softmax来做了一个简单的松弛方案，使得整个搜索空间变为可微的。softmax的公式如图，非常简单的公式。   </p><script type="math/tex; mode=display">S_{i}=\frac{e^{i}}{\sum_{j} e^{j}}</script><p>扩展到本文中，就是这样的：</p><script type="math/tex; mode=display">\overline{O}^{(i, j)}(x)=\sum_{o \in \mathcal{O}} \frac{\exp \left(\alpha_{o}^{(i, j)}\right)}{\sum_{o^{\prime} \in \mathcal{O}} \exp \left(\alpha_{o^{\prime}}^{(i, j)}\right)} o(x)</script><p>其中<script type="math/tex">\alpha^{(i, j)}</script>是一个向量，表示的是节点$ (i, j) $中的混合操作，$\overline{o}^{(i, j)}$是混合概率操作， $ \mathcal{O} $是候选操作集合。</p><p>$\alpha$ 就是整体框架的向量表示。</p><p>现在，我们就把操作选择从不可微转化为可微操作。</p><p>我们最后在选择操作是就是选择概率最大的选项。</p><script type="math/tex; mode=display">o^{(i, j)}=\operatorname{argmax}_{o \in \mathcal{O}} \alpha_{o}^{(i, j)}</script><h4 id="2-建模为双层优化问题"><a href="#2-建模为双层优化问题" class="headerlink" title="2. 建模为双层优化问题"></a>2. 建模为双层优化问题</h4><p>先定义两个loss： $L_{train}$和$L_{val}$。那么很显然，我们的最终目标是找到一个$\alpha$ 使得$L_{val}$最小，但是需要注意的是$L_{val}$不仅有关于$\alpha$，还有关于$w$。</p><p>我们就可以得到目标函数：</p><script type="math/tex; mode=display">\min _{\alpha} \mathcal{L}_{v a l}\left(w, \alpha\right)</script><p>但是必须注意的是，$w$是相关于$\alpha$的，架构$\alpha$的变化会带来$w$的改变，所以目标函数要变成：</p><script type="math/tex; mode=display">\min _{\alpha} \mathcal{L}_{v a l}\left(w^{*}(\alpha), \alpha\right)</script><p>而$w$与$\alpha$的真正关系是怎样的呢？其实是$w$的选取，其实是相对于固定架构$\alpha$，取得最小的$L_{train}$时的$w^{*}$，也就是说，关于$w^{*}$选取的目标函数是：</p><script type="math/tex; mode=display">w^{*}(\alpha)=\operatorname{argmin}_{w}  \mathcal{L}_{t r a i n}(w, \alpha)</script><p>现在，我们得到了最后的优化函数，它是一个双层优化问题：</p><script type="math/tex; mode=display">\begin{array}{cl}{\min _{\alpha}} & {\mathcal{L}_{v a l}\left(w^{*}(\alpha), \alpha\right)} \\ {\text { s.t. }} & {w^{*}(\alpha)=\operatorname{argmin}_{w} \mathcal{L}_{\text {train}}(w, \alpha)}\end{array}</script><p>（不太好理解的话，架构$\alpha$这个参数的地位有点类似于lr学习率，但是显然比简单线性增减的学习率复杂太多）。</p><p>因为下层子问题的自变量$w$与上层问题的$L_{val}$无法直接用表达式表达出来，所以这个问题无法被简化为单层优化问题。双层问题的求解是非常复杂的，$\alpha$的每一次变化，$w$就需要重新求解一次。整个问题的时间复杂度可以达到$\mathrm{O}(|\mathrm{a}||\mathrm{w}|)$。</p><p>而如何能够在实际中解决这个问题，我们需要采用一些近似优化的方法。</p><h4 id="3-近似迭代优化：梯度下降"><a href="#3-近似迭代优化：梯度下降" class="headerlink" title="3. 近似迭代优化：梯度下降"></a>3. 近似迭代优化：梯度下降</h4><p>darts中采用了近似迭代的方法来解决这个问题，通过$w$和$\alpha$分别在权重和构架空间中的梯度下降步骤之间交替来完成优化。</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1k697frydj31o60e2tph.jpg" alt></p><p>我们来看这个优化算法，在第k步的时候，首先采用$\alpha{k-1}$的架构，通过$ \mathcal{L}_{t r a i n}\left(w_{k-1}, \alpha_{k-1}\right) $获得现在的权重$ w{k}$，利用梯度更新一步$ w{k}$， 再固定$ w{k}$，进行主问题的优化：</p><script type="math/tex; mode=display">\mathcal{L}_{v a l}\left(w^{\prime}, a_{k-1}\right)=\mathcal{L}_{v a l}\left(w_{k}-\xi \nabla_{w} \mathcal{L}_{t r a i n}\left(w_{k}, \alpha_{k-1}\right), a_{k-1}\right)</script><p>其中，$\xi $是$ w$的学习率。$w_{k}-\xi \nabla_{w} \mathcal{L}_{t r a i n}\left(w_{k}, \alpha_{k-1}\right)$这一项就是表示$ w{k}$的一步梯度更新。</p><p>这个式子的背后动机是，寻找一个架构$\alpha{k}$使得权重$ w{k}$在进行单步梯度下降后$L_{val}$会更低。这种优化方式采用的是Stackelberg game，但是没有收敛担保，只有实践证明。同时我们发现采用momentum梯度更新，我们的推论依旧是成立的。</p><p>由上面的推断，我们可以得到构架a的梯度表示：</p><script type="math/tex; mode=display">\nabla_{\alpha} \mathcal{L}_{v a l}\left(w^{\prime}, \alpha\right)-\xi \nabla_{\alpha, w}^{2} \mathcal{L}_{t r a i n}(w, \alpha) \nabla_{w^{\prime}} \mathcal{L}_{v a l}\left(w^{\prime}, \alpha\right)</script><p>可以注意到第二项中有一个二次梯度，这一项的计算是极为复杂的，所幸微分是可以有近似操作的。</p><script type="math/tex; mode=display">\nabla_{\alpha, w}^{2} \mathcal{L}_{t r a i n}(w, \alpha) \nabla_{w^{\prime}} \mathcal{L}_{v a l}\left(w^{\prime}, \alpha\right) \approx \frac{\nabla_{\alpha} \mathcal{L}_{t r a i n}\left(w^{+}, \alpha\right)-\nabla_{\alpha} \mathcal{L}_{t r a i n}\left(w^{-}, \alpha\right)}{2 \epsilon}</script><p>其中，有$w^{+}=w+\epsilon \nabla_{w^{\prime}} \mathcal{L}_{v a l}\left(w^{\prime}, \alpha\right)$和$w^{-}=w-\epsilon \nabla_{w^{\prime}} \mathcal{L}_{v a l}\left(w^{\prime}, \alpha\right)$。</p><p>计算有限差分只需要两次权值前传和两次向后传递，复杂度从$\mathrm{O}(|\mathrm{a}||\mathrm{w}|)$降低为$\mathrm{O}(|\mathrm{a}|+|\mathrm{w}|)$。</p><p>可以考虑一个特殊情况，学习率为0的时候，上式就变成了一个一阶近似。而$\alpha$的梯度则完全取决于前一项。这样的话，$\alpha$和$w$就相对独立了，但是这种情况下虽然速度有了提高，效果却下降的厉害。</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1k6lwncmvj31m80u0hdt.jpg" alt></p><h4 id="4-还原为离散网络结构"><a href="#4-还原为离散网络结构" class="headerlink" title="4. 还原为离散网络结构"></a>4. 还原为离散网络结构</h4><p>最后得到了架构的参数a，要将它还原为离散的网络构架，我们进行两步操作：</p><ol><li><p>为每个节点选取最强的k个预处理，这个k的选取依据以下公式。为了和其他网络结构保持可对比性，我们的卷积单元k=2，循环单元k=1。</p><script type="math/tex; mode=display">\max _{o \in \mathcal{O}, o \neq z e r o} \frac{\exp \left(\alpha_{o}^{(i, j)}\right)}{\sum_{o^{\prime} \in \mathcal{O}} \exp \left(\alpha_{o^{\prime}}^{(i, j)}\right)}</script></li><li><p>以argmax取代所有混合操作，成为最有可能的操作。</p></li></ol><p>以下为两个训练出来的结果：</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g1k6p1emunj31240ki7jt.jpg" width="250," height="250"></p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1k6ooqv18j30oq0w2als.jpg" width="250," height="250"></p><h3 id="2-3-实验结果"><a href="#2-3-实验结果" class="headerlink" title="2.3 实验结果"></a>2.3 实验结果</h3><p>在这部分，具体的实验细节就不提供了，本文中在CIFAR-10数据集上进行CNN的cell训练。对于CNN网络，darts一共训练两种cell：normal cell和reduction cell。区别在于stride，前者为1，后者为2后再网络三分之一处和三分之二处。在Penn Treebank上训练RNN cell。只有一种单元。如下图显示，整个构架搜索是初始化敏感的，CNN cell经过长时间训练后能得到比较好的收敛，但是RNN cell的结果与初始化关系比较密切。</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1k6ung22xj30xw0dkk5b.jpg" alt></p><p>第二部分的评估，是将训练好的cell迁移到ImageNet或者WikiText-2上进行测试。在ImageNet上的效果是比较好的，而WikiText-2上的效果一般，可能原因是文本数据集差异过大。</p><h2 id="第三部分-darts的改进方向"><a href="#第三部分-darts的改进方向" class="headerlink" title="第三部分 darts的改进方向"></a>第三部分 darts的改进方向</h2><p>在学习darts过程中想到的一些改进方向，与其他工作带来的启发。</p><p>darts上有几个点是有待完善的</p><ol><li>它的近似优化是简单的w更新后a更新，这个操作只是实践有效，但是应该是有改进的空间；</li><li>它对于RNN cell 的初始化敏感是需要优化的</li><li>现在的迁移学习就是简单的把cell运用到新的结构上，是否考虑添加distill，可能对于RNN这种表现一般的迁移有更好的效果。</li></ol><p>这个领域中，今后比较有意思的研究点包括： </p><p>研究针对多任务和多目标问题的 NAS； </p><p>研究更加灵活的搜索变量表示，类似 cell 这种方便进行迁移的表示方式； </p><p>挖掘更多的、有难度的 benchmark； </p><p>迁移学习的引入，进一步提高效率。 </p><h2 id="第四部分-疑问"><a href="#第四部分-疑问" class="headerlink" title="第四部分 疑问"></a>第四部分 疑问</h2><ol><li>为什么权值更新采用momentum梯度更新法？</li></ol>]]></content>
    
    <summary type="html">
    
      利用梯度下降进行神经网络架构搜索，和之前的利用强化或者进化来做nas的效率有很大改进。
    
    </summary>
    
      <category term="NAS" scheme="https://jiaoyuzhang.github.io/categories/NAS/"/>
    
    
      <category term="darts" scheme="https://jiaoyuzhang.github.io/tags/darts/"/>
    
      <category term="NAS" scheme="https://jiaoyuzhang.github.io/tags/NAS/"/>
    
      <category term="autoML" scheme="https://jiaoyuzhang.github.io/tags/autoML/"/>
    
      <category term="轻量化卷积" scheme="https://jiaoyuzhang.github.io/tags/%E8%BD%BB%E9%87%8F%E5%8C%96%E5%8D%B7%E7%A7%AF/"/>
    
  </entry>
  
  <entry>
    <title>论文阅读- ShuffleNet</title>
    <link href="https://jiaoyuzhang.github.io/2019/03/27/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ShuffleNet/"/>
    <id>https://jiaoyuzhang.github.io/2019/03/27/论文阅读-ShuffleNet/</id>
    <published>2019-03-27T13:33:49.000Z</published>
    <updated>2019-03-27T13:39:24.460Z</updated>
    
    <content type="html"><![CDATA[<p>论文标题：ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices 【<a href="https://arxiv.org/pdf/1707.01083.pdf" target="_blank" rel="noopener">pdf</a>】</p><p>作者：Xiangyu Zhang∗ Xinyu Zhou∗ Mengxiao Lin Jian Sun</p><p>旷视的轻量化卷积网络。</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>ShuffleNet：能够应用于移动场景的轻量级应用。它的操作限制在10-150MFLOPs。</p><p>这个新结构采用了两种新结构：pointwise group convolution（点群卷积）和channel shuffle（打乱通道）。</p><p>实验采用了ImageNet分类问题和COCO上的目标检测问题，在算力限制40MFLOPs它相比于mobilenetv1在分类问题上有更低的top-1错误率（7.8%）。在ARM-based移动设备上，它和AlexNet准确率可比较的同时速度快上13倍。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>现阶段在解决视觉识别任务时构建更深更大的卷积网络是大势。本文则追求在有限运算次数中追求更高准确率。现有的轻量级模型聚焦在剪枝（pruning）、挤压（compressing）或者低位（low-bit）一个基础神经网络。</p><p>本文注意到标准基础结构比如Xception、ResNeXt由于1<em>1卷积层的巨大消耗在小型网络中表现低效。本文采用pointwise group convolution（PGC）来减少1</em>1卷积层的计算复杂性。为了克服PGC带来的边际效应，本文使用channel shulffle来得到信息在特征层之间流动。</p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>有效的模型设计。GoogleNet在更少复杂性下加深了网络深度。SqueezeNet在准确率维持的同时减少了参数和计算。ResNet使用了bottleneck结构。SENet引入了一个表现良好的轻量级计算的结构单元。</p><p><strong>Group Convolution。</strong>组卷积的概念一开始是AlexNet为了在两个GPU上计算而提出的，在ResNeXt中显示出了它的效率。Depthwise separable convolution在Xception中被使用。最近的MobileNet使用可分卷积在轻量级模型上取得了最先进的结果。本文以全新的形式使用了组卷积和可分卷积。</p><p><strong>Channel Shuffle Operation。</strong>据我们所知，通道洗牌操作之前很少在效率模型中被使用。CNN库cuda-convnet中支持“任意可分卷积”层，在组卷积中等同于任意通道洗牌。但是这样的任意洗牌操作的目的不同，后来也很少被用到。最近，另一个网络也在两阶段卷积中采用了这一创意，但是它没有发现通道洗牌的作用，也没有把它用于小型网络设计。</p><p><strong>模型加速。</strong>模型加速是要在准确保持的情况下加速前向网络（inference）。剪枝网络在保持表现的同时减去了预训练模型的冗余链接。量化和因式分解的目的都是减去冗余计算来加速前向网络。实践中还有利用FFT加速CNN卷积计算。另外，Distilling（蒸馏）将大模型的信息提取到小模型中，使得训练小模型更为简单。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="组卷积中使用通道洗牌"><a href="#组卷积中使用通道洗牌" class="headerlink" title="组卷积中使用通道洗牌"></a>组卷积中使用通道洗牌</h3><p>​    现代卷积网络中通常由重复法人相同结构的构建块组成。其中，目前最为优秀的Xception或ResNeXt在构建块中引入可分卷积或者组卷积，以此来取得可靠能力和计算代价间的完美平衡。然而，本文 注意到它们都没有完整考虑点卷积的开销。比如，ResNeXt中只有3*3层使用了组卷积。结果是在ResNeXt的每个残差单元中点卷积占了93.4%的multiplication-adds操作。在小网络中，昂贵的点卷积导致了通道数受到复杂度的限制，这一点对准确度的降低有显著影响。</p><p>为解决这一问题，一个直接的方法是在点卷积上使用通道可分连接（比如组卷积）。通过确保每次卷积操作只作用在对应的输入通道组上，组卷积显著地减少了计算代价。但是，多次组卷积堆叠在一起会产生边际效应：某一特定通道的输出只来源于输入通道的一部分。图1.a展示了两个堆叠的租卷积层。很显然特定组的输出只相关于组内输入，它使得通道组的信息流被固定在组内，削弱了代表性。</p><p>如果我们让组卷积从不同组间获得输入信息，输入通道和输出通道就会充分相关（图1.b）。特别地，对于上一个组层产生的特征图，我们可以先在组内将通道再次分为子组，再在下一层在组中喂入不同的子组。这一步可以通过通道洗牌（图1. c）高效优雅地完成：假设一个g组的卷积层，它的输出有g<em>n个通道，我们先将输出通道reshape成（g，n）矩阵，将矩阵<em>*转置</em></em>后再拉平。注意，即便两个卷积层组数不同这一步依然有效。另外，通道洗牌是可微的，这意味着它可以被嵌入经段对端训练的网络结构中。</p><p>通道洗牌使得利用多重组卷积构建更强力的网络变为可能。</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g1ho2vtyw2j31ec0luq8i.jpg" alt></p><h3 id="ShuffleNet-Unit"><a href="#ShuffleNet-Unit" class="headerlink" title="ShuffleNet Unit"></a>ShuffleNet Unit</h3><p>利用通道洗牌，本文构建了特别为小型网络设计的全新的ShuffleNet单元。先介绍图2.a中的瓶颈单元设计原则。它是一个残差块（residual block）。在它的残差分支中，本文用计算经济的3<em>3可分卷积来替换3</em>3卷积。然后，本文将第一个点卷积层用点组卷积代替，再接了一个通道洗牌，这就形成了一个ShuffleNet单元（图2.b）。第二个点组卷积的作用是重新覆盖通道维度来适应残差捷径。为简化操作，第二个点组卷积后没有再接通道洗牌，结果也是可以接受的。Batch normalization和非线性化操作都相似于标准残差网络，但是在可分卷积后我们没有使用ReLU。鉴于ShuffleNet可能会和stride一起使用，我们在图2.c做了简单的两个改变：1.在捷径后加了一个3*3平均池化层2.用通道连接concat替换element-wise addition，使得扩发通道维数的操作计算更简单。</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1ho49a3edj31dw0mswkf.jpg" alt></p><p>相较于ResNet和ResNeXt，我们的模型在相同配置下计算更简便。比如，输入为c<em>h</em>w，瓶颈层通道数为m，那么ResNet需要hw（2cm+9m^2）FLOPS，ResNeXt需要hw（2cm+9m^2/g）FLOPS，但是ShuffleNet需要hw（2cm/g+9m）FLOPS，g表示组数。这意味着，同样的计算预算，ShuffleNet可以使用更宽的特征图。</p><p>另外，ShuffleNet只在瓶颈层使用可分卷积。尽管可分卷积在理论上复杂度很低，本文发现在低能量移动设备很难效率实现，导致计算/内存可获得比例比其他维度操作低很多。这个缺点在Xception中也被提及。在ShuffleNet单元，我们只在瓶颈处使用可分卷积。</p><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>整个网络结构构件在ShuffleNet单元上，在表格1中完整展示。</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g1ho4wt4yfj31dw0kqafi.jpg" alt></p><p>网络结构中主要包含了三个阶段的ShuffleNet单元。每个阶段的第一个构建块是步长为2的，其他参数在一层中保持不变，进入下一层时输出通道数为变为2倍。类似于ResNet，本文在每个ShuffleNet单元设置瓶颈通道数为输出通道数的1/4。本文意在提供最为简单的偏好设计，但是也发现经过调参结果会更好。</p><p>在ShuffleNet单元中，组数g控制着点卷积的稀疏度。表格1中显示了不同的g，我们调整了输出通道数来保持计算代价基本不变（~140MFLOPS）。显然，组数越大输出通道数越多（更多的卷积过滤器），也就能编码更多的信息，但是它也意味着每个单独的卷积过滤器因为相关输入通道变少而退化。</p><p>为了使网络结构达到预计的复杂度，我们简单在通道数上应用了一个尺度参数s。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>本文的实验主要在ImageNet2012上进行。实验细节在此不做赘述。</p><p>在ImageNet2012上得实验结果为：</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g1ho5f4ukqj310k0940v0.jpg" alt>采用通道洗牌的方式与不采用通道洗牌的不同结果：</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1ho5yasjzj310q0c2add.jpg" alt><br>它与其他压缩模型的对比：</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1ho6hbpczj314y0u0gxd.jpg" alt></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这篇论文模型压缩的主要起作用的piontwise group convolution，然后channel Shuffle提供了5%的错误率改善。</p>]]></content>
    
    <summary type="html">
    
      ShuffleNet：能够应用于移动场景的轻量级应用。它的操作限制在10-150MFLOPs。这个新结构采用了两种新结构：pointwise group convolution（点群卷积）和channel shuffle（打乱通道）。实验采用了ImageNet分类问题和COCO上的目标检测问题，在算力限制40MFLOPs它相比于mobilenetv1在分类问题上有更低的top-1错误率（7.8%）。在ARM-based移动设备上，它和AlexNet准确率可比较的同时速度快上13倍。
    
    </summary>
    
      <category term="轻量化卷积" scheme="https://jiaoyuzhang.github.io/categories/%E8%BD%BB%E9%87%8F%E5%8C%96%E5%8D%B7%E7%A7%AF/"/>
    
    
      <category term="轻量化卷积" scheme="https://jiaoyuzhang.github.io/tags/%E8%BD%BB%E9%87%8F%E5%8C%96%E5%8D%B7%E7%A7%AF/"/>
    
      <category term="dw convolution" scheme="https://jiaoyuzhang.github.io/tags/dw-convolution/"/>
    
      <category term="group convolution" scheme="https://jiaoyuzhang.github.io/tags/group-convolution/"/>
    
  </entry>
  
  <entry>
    <title>论文阅读-TinyFace GAN</title>
    <link href="https://jiaoyuzhang.github.io/2019/03/27/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-TinyGAN/"/>
    <id>https://jiaoyuzhang.github.io/2019/03/27/论文阅读-TinyGAN/</id>
    <published>2019-03-27T10:55:31.000Z</published>
    <updated>2019-03-27T12:45:24.397Z</updated>
    
    <content type="html"><![CDATA[<p>论文标题：Finding Tiny Faces in the Wild with Generative Adversarial Network 【<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Bai_Finding_Tiny_Faces_CVPR_2018_paper.pdf" target="_blank" rel="noopener">pdf</a>】</p><p>作者：Yancheng Bai， Yongqiang Zhang， Mingli Ding，Bernard Ghanem</p><p>本论文被CVPR2018会议录用，并评为oral层次。GAN自从2014年被提出，至今“有名有姓”的GAN网络已经有超过200种，这次cvpr会议上也有大量的基于GAN的论文，半监督学习的GAN在图像方面依旧大有可为。因此选取了一篇比较有质量的GAN的论文进行研读。</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g1hm52jgi2j31g00rku0y.jpg" alt></p><h2 id="背景与问题描述"><a href="#背景与问题描述" class="headerlink" title="背景与问题描述"></a>背景与问题描述</h2><p>人脸检测（Face Detection）是计算机视觉中的一个基本和重要的问题，是一个许多后续基于人脸的应用程序的关键一步。通常来说，人脸检测包括人脸的解析、验证以及标注和检索等。在过去的几十年里，人脸检测已被广泛研究，众多的准确有效的方法提出了使得在大多数受限的场景下人脸检测的效果都极好。最近的作品关注的是在不受控制的环境下的人脸，由于比例、模糊、姿势、表情和光照的显著变化，这是一个更具挑战性的问题。</p><p>现代人脸探测器在大中型人脸上取得了令人瞩目的效果，但在小人脸上的性能却远远不能令人满意。小脸检测通常是指例如10×10像素这一量级的人脸检测，它目前主要有两大问题：</p><p>第一，小脸由于像素过少，缺乏足够的详细信息来区分相似的背景，比如脸或手的一部分；</p><p>第二，现在的人脸检测器通常使用CNN卷积神经网络架构，采用步长为8、16或32的下采样卷积特征图来表示人脸，这些特征图丢失了大部分空间信息，过于粗糙，无法描述小人脸。</p><p>为了检测小人脸，[28]使用双线性操作直接对图像进行上采样，并对上采样图像进行详尽的人脸搜索。然而，这种方法会增加计算成本，推理时间也会大大增加。此外,图像通常与一个小升级因素放大(最多2×)[28],否则,将生成工件。此外，[1,14,25,37]利用中间的conv feature map表示特定尺度下的人脸，保持了计算量与性能之间的平衡。然而，浅层细粒度的中间conv feature map缺乏识别能力，导致了许多假阳性结果。更重要的是，这些方法不考虑其他挑战，如模糊和照明。</p><p>本篇论文做出了以下三个主要贡献：</p><ol><li>提出了一种新的统一的端到端卷积神经网络人脸检测体系结构，利用超分辨率和细化网络生成真实、清晰的高分辨率图像，并引入鉴别器网络对人脸和非人脸进行分类。</li><li>引入了一种新的丢包方法，使鉴别器网络能够同时分辨真假图像和真伪图像。更重要的是，分类损失用来引导生成网络生成更清晰的人脸，从而更容易分类。</li></ol><ol start="3"><li>最后，证明了提出的方法在从模糊的小人脸恢复清晰高分辨率人脸方面的有效性，并证明了该检测方法在较宽的人脸数据集上，特别是在最具挑战性的硬子集上，其检测性能优于其他最先进的方法。</li></ol><h2 id="算法简介"><a href="#算法简介" class="headerlink" title="算法简介"></a>算法简介</h2><p>本篇论文中，一共使用了三方面的技术：</p><ol><li>Face Detection</li><li>Super-resolution and Reﬁnement Network</li><li>Generative Adversarial Networks</li></ol><h3 id="FaceDetector"><a href="#FaceDetector" class="headerlink" title="FaceDetector"></a>FaceDetector</h3><p>现有的人脸检测方法大致可以分为手工制作的基于特征的方法和基于cnn的方法。</p><p>此处介绍本文中作为基准的MB-FCN。</p><p>MB-FCN：Multi-branch fully convolutional network，多分支人脸检测算法。具体做法是联合中间层feature map + 高层feature map特征，用于检测小尺度人脸，单模型的多分支检测，只需做单次前向预测即可检测图像中所有尺度的人脸，因为不用假定最小可检出人脸尺度，所以MB-FCN可以检出图像中所有尺度的人脸目标。</p><p><img src="http://note.youdao.com/src/01E3DDB023D544CA92042AEF445AE3DD" alt="img"></p><p>如fig 2，MB-FCN包含四个模块：</p><ol><li>共享的提特征主干网，本文使用ImageNet上预训练好的ResNet-50，图像经过主干网梭一把，就可以得到各层feature map啦；</li><li>为每个分支，通过feature map的skip connection操作，concate不同分辨率的feature map，用于检测不同尺度的目标，结合fig 2，就是对不同分辨率的feature map使用到了上、下采样操作，使之尺度一致后再做concate；—- 这种融合多尺度feature map，single process检测不同尺度目标的方式，计算量肯定比使用图像金字塔，做multi process检测的方式，计算量小很多；</li><li>对每个分支而言，通过FCN + multi-task学习的方式使各个分支用于特定尺度范围内的人脸；具体地，FCN先1 x 1 conv来一波以降低feature map的通道数，再接两个1 x 1 conv，输出reg、cls结果；</li><li>得到每个分支的reg、cls结果，将结果转为包含得分的bbox，全局NMS一波，即得到最终结果；</li></ol><h3 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h3><p>在了解它的具体网络结构之前，我们先了解以下GAN。</p><p>GAN也就是对抗生成网络，它通过一个对抗的国车给训练一个生成模型G。它包含两个网络，一个生成器G和一个鉴别器D。训练过程交替优化生成器G和鉴别器D，两者相互竞争。训练生成器器G产生样本欺骗鉴</p><p>别器D，训练鉴别器D从生成器G器生成的样本和真样本中分辨真伪图像。</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1hm6s5txrj30bo08f41e.jpg" alt></p><p>目标函数公式：</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1hm7cnnbqj30f0018q33.jpg" alt></p><p>具体过程：</p><ul><li>G是一个生成图片的网络，它接收一个随机的噪声z，通过这个噪声生成图片，记做G(z)。</li><li>D是一个判别网络，判别一张图片是不是“真实的”。它的输入参数是x，x代表一张图片，输出D（x）代表x为真实图片的概率，如果为1，就代表100%是真实的图片，而输出为0，就代表不可能是真实的图片。</li></ul><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>对于本篇论文，它的模型构建为：</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1hm82ojk3j31f40ns1kx.jpg" alt></p><p>首先，图像输入网络。</p><p>第二步，以MB-FCN检测器作为基准，使用它来从输入图像中裁剪出阳性数据(即人脸)和阴性数据(即非人脸)，用于训练生成器和鉴别器，或者生成感兴趣区域(ROIs)进行测试。</p><p>第三步，训练生成器从低分辨率输入图像中重建一个4倍上采样（也就是4<em>4提高到16</em>16）高分辨率图像。其中，先使用上采样子网络（upsample sub-network），以低分辨率图像作为输入，输出为超分辨率图像。再使用细化子网络（reﬁnement sub-network），这是因为第一步生成的图像是模糊的小人脸，缺乏精细的细节，而且受MSE loss的影响，产生的超分辨率人脸通常是模糊的。</p><p>第四步，鉴别器网络为vgg19架构，具有两个并行的fc层，第一个fc层是对自然真实图像或生成的超分辨率图像进行区分，第二个fc层是对人脸或非人脸进行分类。</p><p>三、四两步交替优化。</p><p>具体的网络结构如下图：</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g1hm8qg49sj31dy0bkgom.jpg" alt></p><p>生成器G中，我们不输入随机噪声，而是输入模糊的小脸。它的损失函数包括三部分，一部分是像素级的损失函数，一部分是对抗损失函数，另外移除了VGG的特征匹配损失换成。</p><h2 id="思考与扩展建议"><a href="#思考与扩展建议" class="headerlink" title="思考与扩展建议"></a>思考与扩展建议</h2><p>本篇论文对于极小的人脸的检测有着比较好的实验效果，但同时，上采样的做法也导致部分非人脸的物体被误认为人脸。</p>]]></content>
    
    <summary type="html">
    
      利用GAN来做极小人脸检测
    
    </summary>
    
      <category term="GAN" scheme="https://jiaoyuzhang.github.io/categories/GAN/"/>
    
    
      <category term="GAN" scheme="https://jiaoyuzhang.github.io/tags/GAN/"/>
    
      <category term="人脸检测" scheme="https://jiaoyuzhang.github.io/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
</feed>
